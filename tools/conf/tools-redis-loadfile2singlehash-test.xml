<configuration>
    <redis>
        <servers>codis1:29001, codis1:29002</servers> <!-- 设置redis/codis地址, 格式为 ip:port -->
        <database>4</database> <!-- 设置导入到redis/codis哪个db，默认有16个db，编号0-15 -->
        <timeout>10000</timeout> <!-- 设置连接redis/codis最大超时,单位ms ,默认2000 -->
        <password></password> <!-- 设置连接redis/codis的密码 -->
    </redis>

    <jedisPool>
        <maxTotal>100</maxTotal> <!-- 设置连接池最大连接数 -->
        <maxIdle>15</maxIdle> <!-- 设置连接池最大空闲连接数 -->
        <minIdle>0</minIdle> <!-- 设置连接池最小空闲连接数 -->
    </jedisPool>

    <load>
        <from>file</from>

        <filename>tools/src/test/resources/tools-redis-loadareamap2.log</filename> <!-- 设置数据文件的路径 -->
        <!--<filename>hdfs://spark1:9000/user/tsingfu/test/tools-redis-loadareamap2.log</filename>-->
        <fileEncode>UTF-8</fileEncode> <!-- 设置数据文件的编码格式 -->
        <columnSeperator>,</columnSeperator> <!-- 设置数据文件字段分隔符 -->

        <hashName>singleHashTest</hashName> <!-- 设置hashkey名 -->

        <fieldIdxes>0,1</fieldIdxes> <!-- 设置哪几列作为 hash 的 field, 支持取多列数据进行组合 -->
        <fieldSeperator>:</fieldSeperator> <!-- 设置多列数据组合hash 的 field名时使用的分隔符 -->
        <valueIdxes>2</valueIdxes> <!-- 设置哪几列作为 hash 的 value，支持写多个，会进行拼接 -->
        <valueSeperator>,</valueSeperator> <!-- 设置多列数据组合hash 的 value时使用的分隔符 -->

        <batchLimit>5</batchLimit> <!-- 设置批量加载(pipeline_hset, hmset)的批次数量 -->

        <numThreads>2</numThreads>
        <method>hmset</method> <!-- 设置加载方法 hset, hmset, pipeline_hset  -->
        <!--<method>pipeline_hset</method> -->

    </load>

</configuration>